<!DOCTYPE html>
<html>
<head>
<style>
body { font-family: Arial; }
</style>
<script>
function constructXmlHttp()
{
        if (window.XMLHttpRequest)
        {
                return new XMLHttpRequest();
        }
        else
        {
                return new ActiveXObject("Microsoft.XMLHTTP");
        }
}

function getXmlHttp()
{
	var xmlhttp = constructXmlHttp();

        xmlhttp.onreadystatechange = function()
        {
                if (xmlhttp.readyState > 2)
                {
                        var responseText = xmlhttp.responseText;
                        var jsonParsed = JSON.parse(responseText);
                        var urlOutput = "";


			if (null != jsonParsed.parent)
                               	urlOutput += "<p><a href='' onclick=\"return getAJAX(" + jsonParsed.parent + ");\">&lt;&lt; back</a></p>";
                       	for (var i = 0; i < jsonParsed.URLs.length; i++)
                       	{
                       	        urlOutput += "<a href='' onclick=\"return getAJAX(" + jsonParsed.URLs[i].key + ");\">";
                       	        urlOutput += jsonParsed.URLs[i].URL + "</a> (" + jsonParsed.URLs[i].count + ")<br />";
                       	}
			if (null != jsonParsed.parent)
				urlOutput += "<p><a href='' onclick=\"return getAJAX(" + jsonParsed.parent + ");\">&lt;&lt; back</a></p>";

	                 document.getElementById("urls").innerHTML = urlOutput;
		}
        };

	return xmlhttp;
}

function deleteAll()
{
        var xmlhttp = constructXmlHttp();

	document.getElementById("urls").innerHTML = "";
        xmlhttp.open("DELETE","./jaxrs/urls", false);
        xmlhttp.send();
}

function postAJAX()
{
	var xmlhttp = getXmlHttp();

	xmlhttp.open("POST","./jaxrs/urls", true);
	xmlhttp.setRequestHeader("Content-type", "application/x-www-form-urlencoded");
	xmlhttp.send("crawl_url=" + document.getElementById('urlkey').value);

	document.getElementById("urls").innerHTML = "Please wait, scanning URL: " + document.getElementById('urlkey').value;

	return false;
}

function getAJAX( getKey)
{
        var xmlhttp = getXmlHttp();

        xmlhttp.open("GET","./jaxrs/urls/" + getKey,true);
        xmlhttp.send();

	return false;

}

</script>
<title>JCrawler</title>
</head>
<body onload="getAJAX(0);">
<a href="/">HOME</a><p/>
<b>Crawl a URL</b><br />
<input type="text" id="urlkey" value="http://" />
<button type="button" onclick="postAJAX();">Submit</button>
<br />
<button type="button" onclick="deleteAll();getAJAX(0);">Reset</button>
<br />
<hr />
<b>Database-stored URL crawls</b> (click links, if any, to see results of the crawl) <p />
<div id="urls">
</div>
<p />
<b>About</b> <br />

This tool is a simple Java-based web crawler. Enter a complete url (beginning with "http://") and that page will be crawled, its links will be stored in the database and any links it finds which are also in that domain will be crawled as well, recursively. It assumes that an absolute URL found on a web page is external to that domain and therefore does not crawl it. 
<p />
<p>
Front page: HTML with JavaScript and AJAX
<br />
Back end: Java Servlet via Tomcat 8, MySQL 5.7, Linux (Ubuntu 16.04.2) on AWS/EC2
<p />
<a href="https://github.com/scottdjohnson/JCrawler">Source code on gituhb</a>
<p />
<a href="javadoc">JavaDoc</a>
</body>
</html>
